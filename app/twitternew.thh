// -*- mode: c++ -*-
#ifndef PQTWITTER_NEW_HH
#define PQTWITTER_NEW_HH 1

#include <boost/random.hpp>
#include <utility>
#include <algorithm>
#include <vector>
#include <deque>
#include <set>
#include <iostream>
#include <stdint.h>
#include <tamer/tamer.hh>
#include <sys/resource.h>
#include "time.hh"
#include "json.hh"
#include "hosts.hh"
#include "mpfd.hh"
#include "sock_helper.hh"
#include "partitioner.hh"
#include "pqlog.hh"
#include "pqmemory.hh"
#include "twitternewshim.hh"

namespace pq {
using tamer::event;
using tamer::preevent;
using tamer::gather_rendezvous;
class TwitterNewPopulator;

#define END_TIME        2147483647
#define BASE_TIME       1000000000
#define LOGIN_WINDOW    1000000
#define OVERLAP         0          // subtracted from last check time to define beg_scan
#define SKEW            100000     // subtracted from now to define end_scan

#define TIMELINE_SANITY_CHECK 0

#define PROG_REPORT_PERIOD 1000
#define RATE_LIMIT_PERIOD  10
#define RATE_LIMIT_THRESH  PROG_REPORT_PERIOD * 10

enum { client_at_barrier = 77 };


// Keep barebones info on each user.
struct TwitterGraphNode {
  public:
    TwitterGraphNode(uint32_t uid);
    inline uint32_t uid() const { return uid_; }
    inline uint32_t nfollowers() const { return nfollowers_; }

    // a specialized comparison method for sorting the user list. this is
    // only used for printing debug info.
    enum CompareField { comp_uid = 0, comp_nfollowers, n_comp };
    struct Compare {
        Compare(CompareField field);
        inline bool operator() (const TwitterGraphNode* a, const TwitterGraphNode* b) const;
        inline bool operator() (const uint32_t& a, const TwitterGraphNode* b) const;
        uint32_t field_;
    };

#if TIMELINE_SANITY_CHECK
  public:
    std::vector<uint32_t> followers_;
    std::vector<uint32_t> posts_;
    std::vector<std::pair<uint32_t, uint32_t>> timeline_;
    std::set<String> fetched_;

    static struct _TimelineCompare {
        bool operator() (const std::pair<uint32_t, uint32_t>& left, uint32_t right) {
            return left.first < right;
        }
    } TimelineCompare;
#endif

  private:
    uint32_t uid_;
    uint32_t nfollowers_;

    friend class TwitterNewPopulator;
};

// Has extra bookkeeping for users that do timeline checks. Each client
// may handle a small subset of such users to split the load across
// processes.
struct TwitterUser : public TwitterGraphNode {
  public:
    TwitterUser(uint32_t uid);

    uint32_t last_read_;
    uint32_t last_subscribe_;
    tamer::event<uint32_t> checking_;
};

enum TwitterOp { op_post = 0, op_subscribe, op_logout, op_check, n_op };

class TwitterNewPopulator {
  public:
    typedef boost::mt19937 generator_type;
    typedef boost::random_number_generator<boost::mt19937> rng_type;
    typedef boost::random::discrete_distribution<> op_dist_type;
    typedef boost::random::discrete_distribution<> post_dist_type;
    typedef boost::random::uniform_int_distribution<> uni_dist_type;

    TwitterNewPopulator(const Json& param);
    ~TwitterNewPopulator();

    inline uint32_t ngroups() const { return ngroups_; }
    inline uint32_t groupid() const { return groupid_; }
    inline uint32_t duration() const { return duration_; }
    inline uint32_t popduration() const { return popduration_; }
    inline uint32_t postlimit() const { return postlimit_; }
    inline uint32_t checklimit() const { return checklimit_; }
    inline double pct_active() const { return pct_active_; }
    inline bool initialize() const { return initialize_; }
    inline bool populate() const { return populate_; }
    inline bool execute() const { return execute_; }
    inline bool push() const { return push_; }
    inline bool pull() const { return pull_; }
    inline bool pull_celeb() const { return celebthresh_; }
    inline bool fetch() const { return fetch_; }
    inline bool subtables() const { return subtables_; }
    inline bool eager() const { return eager_; }
    inline bool prevalidate() const { return prevalidate_; }
    inline bool prevalidate_inactive() const { return prevalidate_inactive_; }
    inline bool prevalidate_before_sub() const { return prevalidate_before_sub_; }
    inline bool writearound() const { return writearound_; }
    inline bool report() const { return report_ && ngroups_ > 1; }
    inline bool log() const { return log_; }
    inline bool log_rtt() const { return log_rtt_; }
    inline bool synchronous() const { return synchronous_; }
    inline bool binary() const { return binary_; }
    inline bool verbose() const { return verbose_; }
    inline String print_table() const { return print_table_; }
    inline const Host* master() { return master_; }

    class managed_iterator {
      public:
        typedef std::vector<TwitterGraphNode*> users_type;

        managed_iterator(uint32_t idx, uint32_t skip, users_type& users)
            : idx_(idx), skip_(skip), users_(users) {
        }

        uint32_t operator*() {
            return users_[idx_]->uid();
        }

        managed_iterator& operator++() {
            if (idx_ + skip_ < users_.size())
                idx_ += skip_;
            else
                idx_ = users_.size();
            return *this;
        }

        bool operator!=(const managed_iterator& other) {
            return idx_ != other.idx_;
        }

        managed_iterator& operator=(const managed_iterator& other) {
            idx_ = other.idx_;
            skip_ = other.skip_;
            users_ = other.users_;
            return *this;
        }

      private:
        uint32_t idx_;
        uint32_t skip_;
        users_type& users_;
    };

    inline auto begin_managed() -> managed_iterator;
    inline auto end_managed() -> managed_iterator;
    inline TwitterUser* managed_user(uint32_t user);
    inline const TwitterGraphNode* user(uint32_t user) const { return users_[user]; }
    inline bool is_celebrity(uint32_t user) const;

    void make_subscriptions(generator_type& gen, std::vector<std::pair<uint32_t, uint32_t>>& subs);
    void print_subscription_statistics(std::ostream& stream);

    inline uint32_t rand_op(generator_type& gen) { return op_dist_(gen); }
    inline uint32_t rand_user_all(generator_type& gen) { return uni_dist_(gen); }
    inline uint32_t rand_user_post(generator_type& gen) { return post_dist_(gen); }
    inline uint32_t rand_user_managed(generator_type& gen);

    static const char tweet_data[];

  private:
    uint32_t nusers_;
    uint32_t ngroups_;
    uint32_t groupid_;
    uint32_t duration_;
    uint32_t popduration_;
    uint32_t postlimit_;
    uint32_t checklimit_;
    bool initialize_;
    bool populate_;
    bool execute_;
    bool push_;
    bool pull_;
    bool fetch_;
    bool subtables_;
    bool eager_;
    bool prevalidate_;
    bool prevalidate_inactive_;
    bool prevalidate_before_sub_;
    bool writearound_;
    bool report_;
    bool log_;
    bool log_rtt_;
    bool synchronous_;
    bool visualize_;
    bool binary_;
    bool verbose_;
    String print_table_;
    const Host* master_;
    uint32_t celebthresh_;
    double pct_active_;
    String graph_file_;
    uint32_t min_followers_;
    uint32_t min_subs_;
    uint32_t max_subs_;
    uint32_t max_followers_;
    double shape_;

    std::vector<TwitterGraphNode*> users_;
    op_dist_type op_dist_;
    post_dist_type post_dist_;
    uni_dist_type uni_dist_;
    uni_dist_type group_uni_dist_;

    TwitterNewPopulator(const TwitterNewPopulator&) = delete;
    TwitterNewPopulator& operator=(const TwitterNewPopulator&) = delete;

    uint32_t* subscribe_probabilities(generator_type& gen);
    void import_subscriptions(generator_type& gen, std::vector<std::pair<uint32_t, uint32_t>>& subs);
    void synthetic_subscriptions(generator_type& gen, std::vector<std::pair<uint32_t, uint32_t>>& subs);
    void finish_make_subscriptions(generator_type& gen);
    void make_users();
    bool in_group(uint32_t u) const;
};

inline auto TwitterNewPopulator::begin_managed() -> TwitterNewPopulator::managed_iterator {
    return managed_iterator(groupid_, ngroups_, users_);
}

inline auto TwitterNewPopulator::end_managed() -> TwitterNewPopulator::managed_iterator {
    return managed_iterator(users_.size(), ngroups_, users_);
}

inline TwitterUser* TwitterNewPopulator::managed_user(uint32_t user) {
    assert(in_group(user));
    return reinterpret_cast<TwitterUser*>(users_[user]);
}

inline uint32_t TwitterNewPopulator::rand_user_managed(generator_type& gen) {
    uint32_t randu;
    while ((randu = group_uni_dist_(gen) * ngroups_ + groupid_) >= nusers_ );
    return randu;
}

inline bool TwitterNewPopulator::is_celebrity(uint32_t user) const {
    return (celebthresh_ && (users_[user]->nfollowers_ > celebthresh_));
}


class RandomAdapter {
  public:
    RandomAdapter(boost::mt19937& gen) : gen_(gen) { }
    uint32_t operator()(uint32_t arg) { return gen_() % arg; }
  private:
    boost::mt19937& gen_;
};

template <typename S>
class TwitterNewRunner {
  public:
    TwitterNewRunner(S& server, TwitterNewPopulator& tp);

    tamed void initialize(tamer::event<> done);
    tamed void populate(tamer::event<> done);
    tamed void run(tamer::event<> done);

  private:
    S& server_;
    TwitterNewPopulator& tp_;
    std::vector<uint32_t> active_;
    std::vector<uint32_t> inactive_;
    std::deque<uint32_t> loggedin_;
    uint32_t currtime_;
    Log log_;
    uint64_t nrpc_;
    volatile uint32_t barrier_;
    std::vector<tamer::event<>> at_barrier_;
    tamer::fd master_fd_;
    msgpack_fd* master_sync_;
    Json latency_log_;
    bool rtt_log_enabled_;

    template <typename R>
    void subscribe(uint32_t s, uint32_t p, uint32_t time, preevent<R> e);
    tamed void prevalidate(TwitterUser* user, event<> e);
    tamed void check(TwitterUser* user, uint32_t time,
                     uint32_t beg_scan, uint32_t end_scan, event<uint32_t> e);
    tamed void post(uint32_t u, uint32_t time, String value, event<> e);
    tamed void backfill(uint32_t u, uint32_t f, uint32_t time, event<uint32_t> e);
    tamed void select_active(event<> e);

    tamed void wait_for_server_ready(event<> e);
    tamed void periodic_logger(event<> e);
    tamed void drain(gather_rendezvous& r, event<> e);

    tamed void registrar();
    tamed void register_one(tamer::fd fd);
    tamed void register_with_master(event<> e);
    tamed void wait_at_barrier(event<> e);
    tamed void check_barrier(event<> e);
};

template <typename S>
inline TwitterNewRunner<S>::TwitterNewRunner(S& server, TwitterNewPopulator& tp)
    : server_(server), tp_(tp), currtime_(BASE_TIME), log_(tstamp()), nrpc_(0),
      barrier_(0), master_sync_(nullptr), rtt_log_enabled_(false) {
}

tamed template <typename S>
void TwitterNewRunner<S>::registrar() {
    tvars { tamer::fd cfd; }

    master_fd_ = tamer::tcp_listen(tp_.master()->port());

    if (!master_fd_) {
        std::cerr << "listen: " << strerror(-master_fd_.error()) << std::endl;
        mandatory_assert(false);
    }

    while (master_fd_) {
        twait { master_fd_.accept(make_event(cfd)); }
        register_one(cfd);
    }
}

tamed template <typename S>
void TwitterNewRunner<S>::register_one(tamer::fd cfd) {
    tvars {
        msgpack_fd mpfd(cfd);
        Json j;
    }

    while(cfd) {
        j.clear();
        twait { mpfd.read_request(make_event(j)); }

        if (!j || !j.is_a() || j.size() < 2 || !j[0].is_i()) {
            if (!cfd.valid())
                break;
            std::cerr << "got bad request from grouped client: " << j << std::endl;
            mandatory_assert(false);
        }

        mandatory_assert(j[0].as_i() == client_at_barrier);
        mandatory_assert(j[1].as_i() == barrier_);

        twait { check_barrier(make_event()); }
        mpfd.write(Json::array(-client_at_barrier, barrier_ - 1));
    }

    cfd.close();
}

tamed template <typename S>
void TwitterNewRunner<S>::check_barrier(event<> e) {
    at_barrier_.push_back(e);

    if (at_barrier_.size() == tp_.ngroups()) {
        if (tp_.verbose())
            std::cerr << tstamp() << ": passed barrier " << barrier_ << std::endl;

        for (auto& b : at_barrier_)
            b();
        at_barrier_.clear();
        ++barrier_;
    }
}

tamed template <typename S>
void TwitterNewRunner<S>::register_with_master(event<> e) {
    tvars { struct sockaddr_in sin; }

    do {
       twait { tamer::at_delay(0.1, make_event()); }
       twait {
           auto h = tp_.master();
           pq::sock_helper::make_sockaddr(h->name().c_str(), h->port(), sin);
           tamer::tcp_connect(sin.sin_addr, h->port(), make_event(master_fd_));
       }
    } while(!master_fd_);

    if (tp_.verbose())
        std::cerr << "Established connection with master." << std::endl;

    master_sync_ = new msgpack_fd(master_fd_);
    e();
}

tamed template <typename S>
void TwitterNewRunner<S>::wait_at_barrier(event<> e) {
    tvars { Json j; }

    if (tp_.verbose())
        std::cerr << tstamp() << ": waiting at barrier " << barrier_ << " ("
                  << nrpc_ << " rpcs sent)" << std::endl;

    if (!tp_.groupid())
        check_barrier(e);
    else {
        mandatory_assert(master_sync_);

        twait { 
            master_sync_->call(Json::array(client_at_barrier, barrier_),
                               make_event(j));
        }
        mandatory_assert(j && j[0] == -client_at_barrier && j[1].as_i() == barrier_);

        if (tp_.verbose()) 
            std::cerr << tstamp() << " passed barrier " << barrier_ << std::endl;
        ++barrier_;
        e();
    }
}


tamed template <typename S>
void TwitterNewRunner<S>::wait_for_server_ready(event<> e) {
    tvars {
        Json j;
        bool ready = false;
    }

    do {
        if (tp_.verbose()) { std::cerr << "Checking server readiness." << std::endl; }
        twait { tamer::at_delay_sec(1, make_event()); }
        twait { server_.control(Json().set("is_ready", true), make_event(j)); }
    
        if (!j.is_array())
            j = Json::array(j);

        ready = true;
        for (auto it = j.abegin(); it != j.aend(); ++it)
            if (it->is_b())
                ready &= it->as_b();
            else
                break; // not supported in client, assume server is ready
    }
    while(!ready);

    e();
}

template <typename S> template <typename R>
void TwitterNewRunner<S>::subscribe(uint32_t subscriber, uint32_t poster,
                                    uint32_t time, preevent<R> e) {
    if (tp_.log())
        fprintf(stderr, "%d: subscribe s|%08d|%08d\n", time, subscriber, poster);

    // in client push mode we reverse the subscriber key to make followers list
    server_.subscribe((tp_.push()) ? poster : subscriber,
                      (tp_.push()) ? subscriber : poster,
                      std::move(e));
    ++nrpc_;
}

tamed template <typename S>
void TwitterNewRunner<S>::prevalidate(TwitterUser* user, event<> done) {
    tvars {
        size_t count = 0;
    }

    twait [String("prevalidate ") + String(user->uid())] {
        server_.timeline_add_count(user->uid(), 0, END_TIME, make_event(count));
    }
    ++nrpc_;
    done();
}

tamed template <typename S>
void TwitterNewRunner<S>::check(TwitterUser* user, uint32_t time,
                                uint32_t beg_scan, uint32_t end_scan,
                                event<uint32_t> done) {
    tvars {
        typename S::scan_result sr;
        size_t count = 0;
        uint64_t rtt;
        std::stringstream buf;
    }

    user->checking_ = done;

    if (tp_.log_rtt() && rtt_log_enabled_)
        rtt = tstamp();

    buf << "twtl " << user->uid() << " " << beg_scan << " " << end_scan;
    if (tp_.fetch() || tp_.log() || TIMELINE_SANITY_CHECK) {
        twait [buf.str()] {
            server_.timeline_scan(user->uid(), beg_scan, end_scan,
                                  make_event(sr));
        }
        count = sr.size();

        if (tp_.log()) {
            fprintf(stderr, "%d: scan [t|%08u|%010u, t|%08u|%010u)\n",
                    time, user->uid(), beg_scan, user->uid(), end_scan);

            for (auto it = sr.begin(); it != sr.end(); ++it) {
                if (tp_.binary()) {
                    std::cerr << "  t|" << read_in_net_order<uint32_t>(it->key().data() + 2)
                                  << "|" << read_in_net_order<uint32_t>(it->key().data() + 7)
                                  << "|" << read_in_net_order<uint32_t>(it->key().data() + 12)
                                  << ": " << it->value() << "\n";
                }
                else
                    std::cerr << "  " << it->key() << ": " << it->value() << "\n";
            }
        }

#if TIMELINE_SANITY_CHECK
        {
            for (auto it = sr.begin(); it != sr.end(); ++it)
                if (tp_.binary())
                    user->fetched_.insert(String(read_in_net_order<uint32_t>(it->key().data() + 7)) + " " +
                                          String(read_in_net_order<uint32_t>(it->key().data() + 12)));
                else
                    user->fetched_.insert(Str(it->key().data() + 11, 10) + " " +
                                          Str(it->key().data() + 22, 8));
        }
#endif
    }
    else
        twait [buf.str()] {
            server_.timeline_add_count(user->uid(), beg_scan, end_scan,
                                       make_event(count));
        }

    if (tp_.log_rtt()) {
        bool aftersub = (user->last_subscribe_ && user->last_subscribe_ < time);
        if (aftersub)
            user->last_subscribe_ = 0;

        if (rtt_log_enabled_) {
            uint64_t t = tstamp();
            latency_log_["timeline"]["rtt"].push_back(t - rtt);
            latency_log_["timeline"]["time"].push_back(t);
            latency_log_["timeline"]["vtime"].push_back(time);
            latency_log_["timeline"]["aftersub"].push_back(aftersub);
        }
    }

    ++nrpc_;
    done(done.result() + count);
}

tamed template <typename S>
void TwitterNewRunner<S>::post(uint32_t u, uint32_t time, String value, event<> e) {
    tvars {
        uint32_t s;
        typename S::scan_result sr;
        uint64_t rtt;
        tamer::gather_rendezvous gr;
    }

    if (tp_.log())
        fprintf(stderr, "%d: post p|%08d|%010d\n", time, u, time);

    if (tp_.log_rtt() && rtt_log_enabled_)
        rtt = tstamp();

    server_.post(u, time, value, tp_.is_celebrity(u), gr.make_event());
    ++nrpc_;

    if (tp_.push()) {
        server_.follower_scan(u, gr.make_event(sr));
        twait(gr);
        ++nrpc_;

        server_.prepare_push_post(u, time, value);

        for (auto it = sr.begin(); it != sr.end(); ++it) {
            if (tp_.binary())
                s = read_in_net_order<uint32_t>(it->key().data() + 7);
            else
                s = Str(it->key().data() + 11, 8).to_i();
            server_.push_post(s, gr.make_event());
            ++nrpc_;
        }
    }

#if TIMELINE_SANITY_CHECK
    {
        assert(!tp_.groupid() && "Sanity check requires single client group.");
        TwitterUser* poster = tp_.managed_user(u);
        poster->posts_.push_back(time);

        for (auto& i : poster->followers_) {
            TwitterUser* f = tp_.managed_user(i);
            if (find(f->timeline_.begin(), f->timeline_.end(), std::make_pair(time, u)) == f->timeline_.end())
                f->timeline_.push_back(std::make_pair(time, u));
        }
    }
#endif

    twait ["twpush"] (gr);

    if (tp_.log_rtt() && rtt_log_enabled_) {
        uint64_t t = tstamp();
        latency_log_["post"]["rtt"].push_back(t - rtt);
        latency_log_["post"]["time"].push_back(t);
        latency_log_["post"]["vtime"].push_back(time);
    }

    e();
}

tamed template <typename S>
void TwitterNewRunner<S>::backfill(uint32_t u, uint32_t f, uint32_t time, event<uint32_t> e) {
    assert(tp_.push());

    tvars {
        uint32_t ptime;
        typename S::scan_result sr;
        tamer::gather_rendezvous gr;
    }

    server_.post_scan(f, time - LOGIN_WINDOW, time, gr.make_event(sr));
    twait ["twbackfill"] (gr);
    ++nrpc_;

    for (auto it = sr.begin(); it != sr.end(); ++it) {
        if (tp_.binary())
            ptime = read_in_net_order<uint32_t>(it->key().data() + 7);
        else
            ptime = Str(it->key().data() + 11, 10).to_i();
        server_.prepare_push_post(f, ptime, it->value());
        server_.push_post(u, gr.make_event());
        ++nrpc_;
    }
    twait ["twbackfill2"] (gr);

    e(e.result() + sr.size());
}

tamed template <typename S>
void TwitterNewRunner<S>::initialize(tamer::event<> done) {
    if (tp_.initialize()) {
        twait { wait_for_server_ready(make_event()); }
        twait { server_.initialize(make_event()); }
    }
    done();
}

tamed template <typename S>
void TwitterNewRunner<S>::populate(tamer::event<> done) {
    tvars {
        boost::mt19937 gen;
        uint32_t s;
        uint32_t post_end_time = this->currtime_ + this->tp_.popduration();
        std::vector<std::pair<uint32_t, uint32_t>> subs;
        Json j;
        tamer::gather_rendezvous gr;
    }
    gen.seed(112181 + tp_.groupid());

    if (!tp_.populate() && !tp_.execute())
        goto finish;

    if (tp_.verbose()) { std::cerr << "Creating social graph." << std::endl; }
    tp_.make_subscriptions(gen, subs);
    if (!tp_.groupid())
        tp_.print_subscription_statistics(std::cerr);

    // in some experiments we pre-populate the servers using another process
    if (!tp_.populate())
        goto finish;

    twait { wait_for_server_ready(make_event()); }

    // in some experiments we want to prevalidate before adding the
    // subscriptions so that the first validation in the experiment for each
    // user has to perform some updates. if we are not prevaldiating then
    // there is no reason to select active users in this phase
    if (tp_.prevalidate_before_sub())
        twait { select_active(make_event()); }

    if (tp_.verbose()) { std::cerr << "Building subscription table." << std::endl; }
    for (s = 0; s != subs.size(); ++s) {
        subscribe(subs[s].first, subs[s].second, currtime_, gr.make_event());
        twait ["twpace"] { server_.pace(make_event()); }

        if (tp_.verbose() && s && s % (subs.size() / 10) == 0)
            std::cerr << s / (subs.size() / 10) * 10 << "% complete" << std::endl;
    }

    for (auto u = tp_.begin_managed(); u != tp_.end_managed(); ++u)
        if (tp_.is_celebrity(*u))
            server_.mark_celebrity(*u, gr.make_event());
    twait { drain(gr, make_event()); }

    if (tp_.verbose()) { std::cerr << "Populating twittersphere." << std::endl; }
    while(currtime_ < post_end_time) {
        post(tp_.rand_user_post(gen), currtime_,
             String(TwitterNewPopulator::tweet_data, TWEET_LENGTH), gr.make_event());
        ++currtime_;

        twait{ server_.pace(make_event()); }
    }
    twait { drain(gr, make_event()); }

    twait { server_.control(Json().set("flush_db_queue", true), make_event(j)); }

    finish:
    currtime_ = post_end_time;
    done();
}

tamed template <typename S>
void TwitterNewRunner<S>::select_active(event<> done) {
    tvars {
        boost::mt19937 gen;
        boost::uniform_real<> active_rng(0,100);
        TwitterNewPopulator::managed_iterator uit = this->tp_.end_managed();
        uint32_t u;
        tamer::gather_rendezvous gr;
    }

    gen.seed(13918 + tp_.groupid());

    // create a working set of users
    if (tp_.verbose()) { std::cerr << "Selecting active users." << std::endl; }
    for (uit = tp_.begin_managed(); uit != tp_.end_managed(); ++uit) {
        if (active_rng(gen) >= tp_.pct_active()) {
            inactive_.push_back(*uit);
            continue;
        }

        active_.push_back(*uit);

        if (tp_.prevalidate()) {
            prevalidate(tp_.managed_user(*uit), gr.make_event());
            twait{ server_.pace(make_event()); }
        }
    }
    twait { drain(gr, make_event()); }

    if (tp_.prevalidate_inactive()) {
        for (u = 0; u != inactive_.size(); ++u) {
            prevalidate(tp_.managed_user(inactive_[u]), gr.make_event());
            twait{ server_.pace(make_event()); }
        }
        twait { drain(gr, make_event()); }
    }

    std::random_shuffle(active_.begin(), active_.end(), RandomAdapter(gen));
    if (active_.empty() && tp_.pct_active())
        assert(false && "There were no active users selected.");

    done();
}

tamed template <typename S>
void TwitterNewRunner<S>::periodic_logger(event<> done) {
    tvars {
        struct rusage u, lu;
        uint64_t now, before, utime, stime;
        double scale = 1.0 / 10000;
    }
    before = 0;
    memset(&lu, 0, sizeof(struct rusage));

    while(done) {
        mandatory_assert(getrusage(RUSAGE_SELF, &u) == 0, "Failed to getrusage.");
        now = tstamp();
        utime = tv2us(u.ru_utime) - tv2us(lu.ru_utime);
        stime = tv2us(u.ru_stime) - tv2us(lu.ru_stime);

        log_.record_at("mem_max_rss_mb", now, maxrss_mb(u.ru_maxrss));
        log_.record_at("utime_us", now, utime);
        log_.record_at("stime_us", now, stime);
        log_.record_at("cpu_pct", now, (before) ? ((utime + stime) * scale / fromus(now - before)) : 0);

        lu = u;
        before = now;
        twait volatile { tamer::at_delay_sec(1, make_event()); }
    }
}

tamed template <typename S>
void TwitterNewRunner<S>::drain(gather_rendezvous& r, event<> e) {
    // we are waiting for the "top level" events gathered in the
    // rendezvous r to be triggered. however, some shim layers may buffer
    // I/O, causing the program to hang if not flushed. it is possible
    // for some lower level events that are triggered by the flushing
    // to generate more I/O, hence the need for the loop.
    while(r.has_waiting()) {
        twait { server_.flush(make_event()); }
        twait { tamer::at_delay_msec(1, make_event()); }
    }
    e();
}

tamed template <typename S>
void TwitterNewRunner<S>::run(tamer::event<> done) {
    tvars {
        boost::mt19937 gen;
        struct rusage ru[2];
        struct timeval tv[2];
        uint32_t beg_time = this->currtime_;
        uint32_t end_time = beg_time + this->tp_.duration();
        uint32_t postlimit = this->tp_.postlimit();
        uint32_t checklimit = this->tp_.checklimit();
        uint32_t u, beg_scan, end_scan, slot, n, lastprog = 0;
        uint32_t npost = 0, nbackpost = 0, nsubscribe = 0,
                 nlogout = 0, ncheck = 0, nread = 0, nfull = 0;
        uint32_t next_checker = 0;
        uint32_t slowest = 0;
        bool rate_limit = false;
        TwitterUser* user = NULL;
        typename S::scan_result scan_result;
        Json old_stats, stats, logs, j;
        tamer::gather_rendezvous gr;
    }

    if (!tp_.execute()) {
        done();
        return;
    }

    if (tp_.groupid())
        twait { register_with_master(make_event()); }
    else if (tp_.ngroups() > 1)
        registrar();

    if (!tp_.groupid())
        twait { wait_for_server_ready(make_event()); }

    if (tp_.ngroups() > 1)
        twait { wait_at_barrier(make_event()); }

    if (active_.empty())
        twait { select_active(make_event()); }

    if (tp_.ngroups() > 1)
        twait { wait_at_barrier(make_event()); }

    if (!tp_.groupid()) {
        twait { server_.control(Json().set("clear_log", true), make_event(j)); }
        server_.stats(gr.make_event(old_stats));        
        twait { drain(gr, make_event()); }
        if (tp_.verbose()) { std::cerr << "Master ready." << std::endl; }
    }

    if (tp_.ngroups() > 1)
        twait { wait_at_barrier(make_event()); }

    log_.clear();
    periodic_logger(done);
    gen.seed(13 + tp_.groupid());
    rtt_log_enabled_ = true;

    if (tp_.verbose()) { std::cerr << "Starting workload." << std::endl; }
    getrusage(RUSAGE_SELF, &ru[0]);
    gettimeofday(&tv[0], 0);

    while (currtime_ < end_time &&
           ((postlimit) ? (npost < postlimit) : true) &&
           ((checklimit) ? (ncheck < checklimit) : true)) {
        user = nullptr;

        switch(tp_.rand_op(gen)) {
            case op_post:
                post(tp_.rand_user_post(gen), currtime_,
                     String(TwitterNewPopulator::tweet_data, TWEET_LENGTH),
                     gr.make_event());

                ++npost;
                break;

            case op_subscribe:
                user = tp_.managed_user(tp_.rand_user_managed(gen));
                uint32_t following;

                do {
                    following = tp_.rand_user_all(gen);
                } while (following == user->uid());

                subscribe(user->uid(), following, currtime_, gr.make_event());
                user->last_subscribe_ = currtime_;
                ++nsubscribe;

                if (tp_.push())
                    backfill(u, following, currtime_, gr.make_event(nbackpost));
#if TIMELINE_SANITY_CHECK
                {
                    TwitterUser* f = tp_.managed_user(following);
                    auto pbegin = lower_bound(f->posts_.begin(), f->posts_.end(), currtime_ - LOGIN_WINDOW);
                    auto pend = lower_bound(f->posts_.begin(), f->posts_.end(), currtime_);

                    if (find(f->followers_.begin(), f->followers_.end(), user->uid()) == f->followers_.end()) {
                        f->followers_.push_back(user->uid());
                        std::sort(f->followers_.begin(), f->followers_.end());
                        while(pbegin != pend) {
                            user->timeline_.push_back(std::make_pair(*pbegin, following));
                            ++pbegin;
                        }
                        std::sort(user->timeline_.begin(), user->timeline_.end());
                    }
                }
#endif
                break;

            case op_logout:
                if (loggedin_.empty())
                    break;

                user = tp_.managed_user(loggedin_.front());
                user->last_read_ = 0;

                if (tp_.log())
                    fprintf(stderr, "%d: logout %08d\n", currtime_, user->uid());

                loggedin_.pop_front();
                ++nlogout;
                break;

            case op_check:
                if (next_checker >= active_.size())
                    next_checker = 0;

                user = tp_.managed_user(active_[next_checker++]);
                if (user->checking_)
                    twait { user->checking_.at_trigger(make_event()); }

                beg_scan = user->last_read_;
                end_scan = currtime_ - SKEW;

                if (!beg_scan) {
                    loggedin_.push_back(user->uid());
                    beg_scan = currtime_ - LOGIN_WINDOW;
                    ++nfull;
                }
                else
                    beg_scan -= OVERLAP;

                user->last_read_ = end_scan;
                check(user, currtime_, beg_scan, end_scan, gr.make_event(nread));
                ++ncheck;
                break;

            default:
                assert(false && "Unknown operation.");
        }

        if (tp_.synchronous())
            twait { drain(gr, make_event()); }
        else
            twait { server_.pace(make_event()); }

        ++currtime_;

        if (tp_.report() && currtime_ % PROG_REPORT_PERIOD == 0) {
            twait { drain(gr, make_event()); }
            twait { server_.update_progress(currtime_, make_event(slowest)); }
            if (currtime_ - slowest >= RATE_LIMIT_THRESH)
                rate_limit = true;
            else
                rate_limit = false;
        }

        if (rate_limit && currtime_ % RATE_LIMIT_PERIOD == 0)
            twait { tamer::at_delay(0.001, make_event()); }

        if (tp_.verbose()) {
            uint32_t prog;
            uint32_t goal;

            if (postlimit) {
                prog = npost;
                goal = postlimit;
            }
            else if (checklimit) {
                prog = ncheck;
                goal = checklimit;
            }
            else {
                prog = currtime_ - beg_time;
                goal = tp_.duration();
            }

            uint32_t frac = goal / 10;
            if (prog && prog != lastprog && prog % frac == 0) {
                lastprog = prog;
                std::cerr << prog / frac * 10 << "% complete" << std::endl;
            }
        }
    }
    twait { drain(gr, make_event()); }

    rtt_log_enabled_ = false;

    // do a final scan for every loggedin user. this helps to ensure that
    // each distributed experiment does roughly the same amount of work
    // despite differences in rpc ordering
    if (tp_.verbose()) { std::cerr << "Final scan." << std::endl; }
    for (u = 0; u < active_.size(); ++u) {
        user = tp_.managed_user(active_[u]);
        if (user->last_read_) {
            check(user, currtime_, user->last_read_, currtime_, gr.make_event(nread));
            twait { server_.pace(make_event()); }
        }
    }
    twait { drain(gr, make_event()); }

#if TIMELINE_SANITY_CHECK
    {
        bool insane = false;
        for (u = 0; u < active_.size(); ++u) {
            user = tp_.managed_user(active_[u]);
            size_t expected = user->timeline_.size();
            size_t actual = user->fetched_.size();

            if (actual != expected) {
                if (!insane) {
                    std::cerr << "SANITY CHECK: Incorrect number of fetched posts!" << std::endl;
                    insane = true;
                }

                std::cerr << "  (user: " << user->uid() << ", expected: " << expected
                          << ", actual: " << actual << ")" << std::endl;

                /*
                std::cerr << "Expected Posts:" << std::endl;
                for (auto it = user->timeline_.begin(); it != user->timeline_.end(); ++it)
                    std::cerr << "  " << it->first << " " << it->second << std::endl;

                std::cerr << "Fetched Posts:" << std::endl;
                for (auto it = user->fetched_.begin(); it != user->fetched_.end(); ++it)
                    std::cerr << "  " << *it << std::endl;
                */
            }
        }

        mandatory_assert(!insane);
    }
#endif

    if (tp_.ngroups() > 1) {
        twait { wait_at_barrier(make_event()); }

        master_fd_.close();
        if (tp_.groupid())
            delete master_sync_;
    }

    getrusage(RUSAGE_SELF, &ru[1]);
    gettimeofday(&tv[1], 0);

    if (!tp_.groupid()) {
        server_.stats(gr.make_event(stats));
        twait { drain(gr, make_event()); }
        twait {
            server_.control(Json().set("print_validation_log", true)
                                  .set("get_log", true),
                            make_event(logs));

            if (tp_.print_table())
                server_.control(Json().set("print_table_keys", tp_.print_table() + "|"),
                                make_event(j));
        }

        if (!stats.is_array()) {
            old_stats = Json::array(old_stats);
            stats = Json::array(stats);
        }

        uint32_t s = 0;
        for (auto it = stats.abegin(); it != stats.aend(); ++it, ++s) {
            (*it)["server_user_time"] -= old_stats[s]["server_user_time"];
            (*it)["server_system_time"] -= old_stats[s]["server_system_time"];
            (*it)["server_wall_time"] -= old_stats[s]["server_wall_time"];
            (*it)["server_wall_time_insert"] -= old_stats[s]["server_wall_time_insert"];
            (*it)["server_wall_time_validate"] -= old_stats[s]["server_wall_time_validate"];
            (*it)["server_wall_time_evict"] -= old_stats[s]["server_wall_time_evict"];
            (*it)["server_wall_time_other"] -= old_stats[s]["server_wall_time_other"];
        }

        stats = Json().set("log", log_.as_json())
                      .set("server_logs", logs)
                      .set("server_stats", stats);
    }
    else
        stats = Json().set("log", log_.as_json());

    if (tp_.log_rtt())
        stats.set("latency", latency_log_);

    stats.set("nposts", npost)
         .set("nbackposts", nbackpost)
         .set("nsubscribes", nsubscribe)
         .set("nchecks", ncheck)
         .set("nfull", nfull)
         .set("nposts_read", nread)
         .set("nactive", active_.size())
         .set("nlogouts", nlogout)
         .set("user_time", to_real(ru[1].ru_utime - ru[0].ru_utime))
         .set("system_time", to_real(ru[1].ru_stime - ru[0].ru_stime))
         .set("wall_time", to_real(tv[1] - tv[0]));
    std::cout << stats.unparse(Json::indent_depth(4)) << std::endl;

    done();
}


class DBPoolParams;
class Server;

tamed void run_twitter_new_local(TwitterNewPopulator& tp, Server& server);

tamed void run_twitter_new_remote(TwitterNewPopulator& tp, int client_port,
                                  const Hosts* hosts, const Partitioner* part,
                                  const Hosts* dbhosts, const DBPoolParams* dbparams);

tamed void run_twitter_new_dbshim(TwitterNewPopulator& tp,
                                  const DBPoolParams& dbparams);

tamed void run_twitter_new_redis(TwitterNewPopulator& tp,
                                 const Hosts* hosts, const Partitioner* part);

tamed void run_twitter_new_memcache(TwitterNewPopulator& tp,
                                    const Hosts* hosts, const Partitioner* part);

} // namespace pq
#endif
